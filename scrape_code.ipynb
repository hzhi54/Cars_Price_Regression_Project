{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fedd0cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time, os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9e31e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_web(pages):\n",
    "    url = pages\n",
    "    response = requests.get(url)\n",
    "    chromedriver = '/Users/zhihuang/Desktop/Metis/Cars_Price_Regression_Project/chromedriver'\n",
    "    os.environ['webdriver.chrome.driver'] = chromedriver\n",
    "    driver = webdriver.Chrome(chromedriver)\n",
    "    driver.get(url)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    search_box = driver.find_element_by_xpath(\"//input[@name='zip']\")\n",
    "    search_box.click()\n",
    "    search_box.send_keys('10001')\n",
    "    search_box.send_keys(Keys.RETURN)\n",
    "    \n",
    "    time.sleep(3)\n",
    "    \n",
    "    name = []\n",
    "    price = []\n",
    "    report = []\n",
    "    accident = []\n",
    "    owner = []\n",
    "    holder = []\n",
    "    history = []\n",
    "    location = []\n",
    "    info = []\n",
    "    \n",
    "    results = int(driver.find_element_by_id('totalResultCount').text.replace(',','').split(' ')[0])\n",
    "    \n",
    "    if results < 1250:\n",
    "        return name, price, accident, owner, holder, history, location, info\n",
    "    \n",
    "    time.sleep(5)\n",
    "    \n",
    "    while True:\n",
    "        soup = BeautifulSoup(driver.page_source, 'html5lib')\n",
    "    \n",
    "        listings = soup.find(class_='srp-list-container--srp')\n",
    "        name += listings.find_all(class_='listing-header')\n",
    "        price += listings.find_all(class_='srp-list-item-price')\n",
    "        report += listings.find_all(class_='title')\n",
    "        location += listings.find_all(class_='srp-list-item-dealership-location')\n",
    "        history += listings.find_all(class_='count')\n",
    "        info += listings.find_all(class_='srp-list-item-basic-info')\n",
    "        \n",
    "        next_button = driver.find_element_by_xpath('//button[text()=\"Next\"]')\n",
    "        next_button.click()\n",
    "        \n",
    "        time.sleep(3)\n",
    "        \n",
    "        if len(name) > 1225:\n",
    "            break\n",
    "    \n",
    "    size = len(name)-150\n",
    "    \n",
    "    for i in range(0,size):\n",
    "        name[i] = name[i].text\n",
    "        price[i] = price[i].text\n",
    "        location[i] = location[i].text\n",
    "        info[i] = info[i].text\n",
    "        history[i] = history[i].get('data-count')\n",
    "        \n",
    "    for i in range(0,len(report),4):\n",
    "        accident.append(report[i].text)\n",
    "        owner.append(report[i+1].text)\n",
    "        holder.append(report[i+2].text)\n",
    "    \n",
    "    time.sleep(1)\n",
    "    driver.close()\n",
    "            \n",
    "    return name[:size], price[:size], accident[:size], owner[:size], holder[:size], history[:size], location[:size], info[:size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6e73f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "932e4d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def savetocsv(raw_name, raw_price, raw_acc, raw_own, raw_hol, raw_his, raw_loc, raw_info, i):    \n",
    "    if len(raw_name) > 0:\n",
    "        raw_year, raw_brand, raw_model = [], [], []\n",
    "        for n in raw_name:\n",
    "#             print(n)\n",
    "            items = n.split(' ')\n",
    "            raw_year.append(int(items[0]))\n",
    "            raw_brand.append(items[1])\n",
    "            raw_model.append('_'.join(items[2:]))\n",
    "            raw_cost = []\n",
    "\n",
    "        for price in raw_price:\n",
    "            cost = price.split(':')[1]\n",
    "            cost = cost.replace('$','')\n",
    "            cost = cost.replace(',','')\n",
    "            raw_cost.append(cost)\n",
    "\n",
    "        raw_city, raw_state = [], []\n",
    "        for loc in raw_loc:\n",
    "            loca = loc.split(':')[1]\n",
    "            loca = loca.split('(')[0]\n",
    "            loca = loca.split(',')\n",
    "            city = loca[0]\n",
    "            state = loca[1]\n",
    "            raw_city.append(city)\n",
    "            raw_state.append(state)\n",
    "\n",
    "        raw_mile, raw_body, raw_engine = [], [], []\n",
    "        # raw_info\n",
    "        for col in raw_info:\n",
    "            info = col.split(' ')\n",
    "            mile = info[1].replace(',','')\n",
    "            if mile == 'N/A':\n",
    "                mile = 0\n",
    "            raw_mile.append(mile)\n",
    "            body = info[5]\n",
    "            raw_body.append(body)\n",
    "            engine = '_'.join(info[7:])\n",
    "            raw_engine.append(engine)\n",
    "\n",
    "        df = pd.DataFrame({'Year': raw_year,\n",
    "             'Brand': raw_brand,\n",
    "             'Model': raw_model,\n",
    "             'Cost': raw_cost,\n",
    "             'City': raw_city,\n",
    "             'State': raw_state,\n",
    "             'Mileage': raw_mile,\n",
    "             'Accident': raw_acc,\n",
    "             'Body': raw_body,\n",
    "             'Engine': raw_engine,\n",
    "             'Owners': raw_own,\n",
    "             'Usefor':raw_hol,\n",
    "             'Services':raw_his})\n",
    "\n",
    "        df.to_csv('carfax_m'+str(i)+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2f525c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = 'https://www.carfax.com/Used-_m14'\n",
    "# scrape_web(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84c3b0e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# url = 'https://www.carfax.com/Used-Cars-in-New-York-NY_c8636'\n",
    "url = 'https://www.carfax.com/Used-_m'\n",
    "\n",
    "# raw_name, raw_price, raw_acc, raw_own, raw_hol, raw_his, raw_loc, raw_info = scrape_web(c_url)\n",
    "# len(raw_name)\n",
    "for i in ['1','2','3','6','8','9']:\n",
    "    c_url = url+str(i)\n",
    "    time.sleep(3)\n",
    "    raw_name, raw_price, raw_acc, raw_own, raw_hol, raw_his, raw_loc, raw_info = scrape_web(c_url)\n",
    "    \n",
    "    time.sleep(3)\n",
    "\n",
    "    savetocsv(raw_name, raw_price, raw_acc, raw_own, raw_hol, raw_his, raw_loc, raw_info, i)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685dff5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:metis] *",
   "language": "python",
   "name": "conda-env-metis-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
